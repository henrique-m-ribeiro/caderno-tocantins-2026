#!/usr/bin/env python3
"""
Script para integrar dados extra√≠dos dos PDFs na Base V01_REVISADA existente.
Mant√©m todas as colunas da V01 e adiciona os novos indicadores.

Autor: Claude Code
Data: 2026-01-28
"""

import pandas as pd
import json
from pathlib import Path
from datetime import datetime
import re

def normalizar_nome_municipio(nome):
    """Normaliza nome de munic√≠pio para matching."""
    nome = str(nome).lower().strip()
    # Remover acentos
    acentos = {
        '√°': 'a', '√†': 'a', '√£': 'a', '√¢': 'a',
        '√©': 'e', '√®': 'e', '√™': 'e',
        '√≠': 'i', '√¨': 'i', '√Æ': 'i',
        '√≥': 'o', '√≤': 'o', '√µ': 'o', '√¥': 'o',
        '√∫': 'u', '√π': 'u', '√ª': 'u',
        '√ß': 'c'
    }
    for a, b in acentos.items():
        nome = nome.replace(a, b)
    # Remover h√≠fens, underscores e espa√ßos extras
    nome = nome.replace('-', ' ').replace('_', ' ')
    nome = ' '.join(nome.split())
    return nome

def integrar_base_v01_com_extraidos():
    """Integra dados extra√≠dos na base V01."""

    print("=" * 80)
    print("INTEGRA√á√ÉO BASE V01 + DADOS EXTRA√çDOS DOS PDFs")
    print("=" * 80)

    # 1. Carregar base V01
    print("\nüìÅ Carregando Base V01_REVISADA...")
    v01 = pd.read_excel('dados/finais/BASE_DADOS_TOCANTINS_V01_REVISADA.xlsx')
    print(f"  ‚úÖ {v01.shape[0]} munic√≠pios √ó {v01.shape[1]} colunas")

    # 2. Carregar dados extra√≠dos (JSONs)
    print("\nüìÅ Carregando dados extra√≠dos dos JSONs v9...")
    json_dir = Path("dados/brutos/extraidos-perfis")
    json_files = sorted(json_dir.glob("*_v9.json"))

    # Consolidar JSONs em DataFrame
    dados_extraidos = []
    for json_file in json_files:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            row = {'municipio_pdf': json_file.stem.replace('_v9', '')}
            row.update(data.get('indicadores', {}))
            dados_extraidos.append(row)

    df_extraidos = pd.DataFrame(dados_extraidos)
    print(f"  ‚úÖ {len(df_extraidos)} munic√≠pios √ó {len(df_extraidos.columns)} colunas")

    # 3. Normalizar nomes para matching
    print("\nüîÑ Normalizando nomes de munic√≠pios...")
    v01['nome_normalizado'] = v01['terr_nome'].apply(normalizar_nome_municipio)
    df_extraidos['nome_normalizado'] = df_extraidos['municipio_pdf'].apply(normalizar_nome_municipio)

    # 4. Fazer merge (left join para manter todos os munic√≠pios da V01)
    print("\nüîó Fazendo merge dos dados...")
    df_integrado = v01.merge(
        df_extraidos.drop(columns=['municipio_pdf']),
        on='nome_normalizado',
        how='left'
    )

    # Remover coluna auxiliar
    df_integrado = df_integrado.drop(columns=['nome_normalizado'])

    print(f"  ‚úÖ Base integrada: {df_integrado.shape[0]} munic√≠pios √ó {df_integrado.shape[1]} colunas")

    # 5. Estat√≠sticas de integra√ß√£o
    print("\nüìä ESTAT√çSTICAS DA INTEGRA√á√ÉO:")

    # Quantos munic√≠pios da V01 receberam dados dos PDFs
    novos_indicadores = [col for col in df_integrado.columns if col not in v01.columns]
    print(f"  Total de colunas na V01: {len(v01.columns)}")
    print(f"  Novos indicadores adicionados: {len(novos_indicadores)}")
    print(f"  Total de colunas na base integrada: {len(df_integrado.columns)}")

    # Contar munic√≠pios com dados
    municipios_com_dados = df_integrado[novos_indicadores].notna().any(axis=1).sum()
    print(f"\n  Munic√≠pios com dados dos PDFs: {municipios_com_dados}/{len(df_integrado)}")
    print(f"  Munic√≠pios sem dados dos PDFs: {len(df_integrado) - municipios_com_dados}")

    # Indicadores por munic√≠pio (apenas novos)
    ind_por_mun = df_integrado[novos_indicadores].notna().sum(axis=1)
    print(f"\n  Novos indicadores por munic√≠pio:")
    print(f"    M√©dia: {ind_por_mun[ind_por_mun > 0].mean():.1f}")
    print(f"    Mediana: {ind_por_mun[ind_por_mun > 0].median():.0f}")
    print(f"    M√≠nimo: {ind_por_mun[ind_por_mun > 0].min():.0f}")
    print(f"    M√°ximo: {ind_por_mun.max():.0f}")

    # 6. Identificar munic√≠pios sem dados
    municipios_sem_dados = df_integrado[ind_por_mun == 0]['terr_nome'].tolist()
    if municipios_sem_dados:
        print(f"\n‚ö†Ô∏è  MUNIC√çPIOS SEM DADOS DOS PDFs ({len(municipios_sem_dados)}):")
        for mun in municipios_sem_dados:
            print(f"    - {mun}")

    # 7. Salvar base integrada
    print("\nüíæ Salvando base integrada...")

    # CSV
    output_csv = Path("dados/finais/BASE_DADOS_TOCANTINS_V02.csv")
    df_integrado.to_csv(output_csv, index=False, encoding='utf-8-sig')
    print(f"  ‚úÖ CSV: {output_csv}")

    # Excel
    output_excel = Path("dados/finais/BASE_DADOS_TOCANTINS_V02.xlsx")
    df_integrado.to_excel(output_excel, index=False, engine='openpyxl')
    print(f"  ‚úÖ Excel: {output_excel}")

    # 8. Gerar novos metadados
    print("\nüìù Gerando metadados dos novos indicadores...")

    # Carregar metadados existentes
    metadados_v01 = pd.read_excel('dados/finais/METADADOS_BASE_DADOS_TOCANTINS_V01_REVISADA.xlsx')

    # Criar metadados para novos indicadores
    novos_metadados = []

    # Categorizar indicadores
    categorias = {
        'idhm': {'dimensao': 'IDH', 'fonte': 'PNUD/Atlas Brasil', 'unidade': '√çndice (0-1)'},
        'pop': {'dimensao': 'Demografia', 'fonte': 'IBGE - Censo', 'unidade': 'Habitantes'},
        'densidade': {'dimensao': 'Demografia', 'fonte': 'IBGE', 'unidade': 'hab/km¬≤'},
        'taxa_urbanizacao': {'dimensao': 'Demografia', 'fonte': 'IBGE - Censo', 'unidade': '%'},
        'pib': {'dimensao': 'Economia', 'fonte': 'IBGE - Contas Regionais', 'unidade': 'R$ (mil)'},
        'vab': {'dimensao': 'Economia', 'fonte': 'IBGE - Contas Regionais', 'unidade': 'R$ (mil)'},
        'emprego': {'dimensao': 'Trabalho', 'fonte': 'CAGED/MTE', 'unidade': 'V√≠nculos'},
        'alfabetizacao': {'dimensao': 'Educa√ß√£o', 'fonte': 'IBGE - Censo', 'unidade': '%'},
        'ideb': {'dimensao': 'Educa√ß√£o', 'fonte': 'INEP', 'unidade': 'Nota (0-10)'},
        'saneamento': {'dimensao': 'Saneamento', 'fonte': 'IBGE - Censo', 'unidade': '%'},
        'agua': {'dimensao': 'Saneamento', 'fonte': 'IBGE - Censo', 'unidade': '%'},
        'esgoto': {'dimensao': 'Saneamento', 'fonte': 'IBGE - Censo', 'unidade': '%'},
        'lixo': {'dimensao': 'Saneamento', 'fonte': 'IBGE - Censo', 'unidade': '%'},
        'fpm': {'dimensao': 'Finan√ßas P√∫blicas', 'fonte': 'Tesouro Nacional', 'unidade': 'R$'},
        'icms': {'dimensao': 'Finan√ßas P√∫blicas', 'fonte': 'SEFAZ-TO', 'unidade': 'R$'},
        'ipva': {'dimensao': 'Finan√ßas P√∫blicas', 'fonte': 'SEFAZ-TO', 'unidade': 'R$'},
        'fundeb': {'dimensao': 'Finan√ßas P√∫blicas', 'fonte': 'Tesouro Nacional', 'unidade': 'R$'},
        'itr': {'dimensao': 'Finan√ßas P√∫blicas', 'fonte': 'Tesouro Nacional', 'unidade': 'R$'},
        'transferencias': {'dimensao': 'Finan√ßas P√∫blicas', 'fonte': 'Tesouro Nacional', 'unidade': 'R$'},
        'estabelecimentos': {'dimensao': 'Sa√∫de', 'fonte': 'DATASUS/CNES', 'unidade': 'Unidades'},
    }

    for indicador in novos_indicadores:
        # Identificar categoria
        categoria = None
        for key, info in categorias.items():
            if key in indicador.lower():
                categoria = info
                break

        if not categoria:
            categoria = {'dimensao': 'Outros', 'fonte': 'SEPLAN-TO', 'unidade': 'N/A'}

        # Extrair ano do nome do indicador
        ano_match = re.search(r'_(\d{4})$', indicador)
        ano = ano_match.group(1) if ano_match else '2024'

        meta = {
            'codigo': indicador,
            'nome_curto': indicador.replace('_', ' ').title(),
            'descricao': f'Indicador extra√≠do do Perfil Socioecon√¥mico SEPLAN-TO 2024',
            'tipo_dado': 'Num√©rico',
            'dimensao': categoria['dimensao'],
            'unidade': categoria['unidade'],
            'fonte': f"SEPLAN-TO - Perfil Socioecon√¥mico 2024 (via {categoria['fonte']})",
            'ano_referencia': ano,
            'data_coleta': '2026-01-28',
            'metodo_coleta': 'Extra√ß√£o automatizada via pdfplumber (Extrator v9)',
            'endpoint_atualizacao': 'https://www.to.gov.br/seplan/perfis-socioeconomicos',
            'periodicidade_atualizacao': 'Anual',
            'observacoes': 'Extra√≠do dos Perfis Socioecon√¥micos Municipais (8¬™ Edi√ß√£o, Dez/2024)',
            'limitacoes': 'Disponibilidade depende da presen√ßa do dado no PDF original'
        }

        novos_metadados.append(meta)

    # Criar DataFrame com novos metadados
    df_novos_metadados = pd.DataFrame(novos_metadados)

    # Concatenar com metadados existentes
    metadados_integrados = pd.concat([metadados_v01, df_novos_metadados], ignore_index=True)

    # Salvar metadados integrados
    output_metadados = Path("dados/finais/METADADOS_BASE_DADOS_TOCANTINS_V02.xlsx")
    metadados_integrados.to_excel(output_metadados, index=False, engine='openpyxl')
    print(f"  ‚úÖ Metadados integrados: {output_metadados}")
    print(f"     Total de indicadores documentados: {len(metadados_integrados)}")
    print(f"     Novos indicadores documentados: {len(df_novos_metadados)}")

    # 9. Resumo final
    print("\n" + "=" * 80)
    print("\n‚úÖ INTEGRA√á√ÉO CONCLU√çDA COM SUCESSO!")
    print("\nüìä RESUMO:")
    print(f"  Base V01 (original):       {v01.shape[0]} munic√≠pios √ó {v01.shape[1]} indicadores")
    print(f"  Novos indicadores:         +{len(novos_indicadores)} indicadores")
    print(f"  Base V02 (integrada):      {df_integrado.shape[0]} munic√≠pios √ó {df_integrado.shape[1]} indicadores")
    print(f"  Metadados V02:             {len(metadados_integrados)} indicadores documentados")

    print("\nüìÅ ARQUIVOS GERADOS:")
    print(f"  ‚úÖ {output_csv}")
    print(f"  ‚úÖ {output_excel}")
    print(f"  ‚úÖ {output_metadados}")

    print("\n" + "=" * 80)

    return df_integrado, metadados_integrados

if __name__ == "__main__":
    df_integrado, metadados = integrar_base_v01_com_extraidos()
